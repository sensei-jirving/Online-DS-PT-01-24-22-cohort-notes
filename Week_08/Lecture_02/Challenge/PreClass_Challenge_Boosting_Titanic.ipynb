{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Challenge Boosting Titanic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sensei-jirving/Online-DS-PT-01.24.22-cohort-notes/blob/main/Week_08/Lecture_02/Challenge/PreClass_Challenge_Boosting_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na9Yu0BGSnJ2"
      },
      "source": [
        "# Boosting Live Class Challenge\n",
        "\n",
        "This is the famous Titanic Dataset. We are predicting whether the passengers survived or died based on the features given."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU6rvmn7yiXH",
        "outputId": "1e48a1f9-91f1-41f1-a467-e4af198bf206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqAgLUBqST7j"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_transformer, make_column_selector\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, \\\n",
        "f1_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbuGQ8Zmgjwn"
      },
      "source": [
        "# Define a function that takes in arguments and prints out a classification report and confusion matrix\n",
        "def evaluate_classification(model, X_test, y_test, cmap='Greens',\n",
        "                            normalize='true', classes=None, figsize=(15,5)):\n",
        "  test_preds = model.predict(X_test)\n",
        "  print(metrics.classification_report(y_test, test_preds, target_names=classes))\n",
        "\n",
        "  fig, ax = plt.subplots(ncols=2, figsize=figsize)\n",
        "  ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap=cmap,\n",
        "                                        display_labels=classes,\n",
        "                                        ax=ax[0])\n",
        "  \n",
        "  ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, cmap=cmap,\n",
        "                                        display_labels=classes, normalize='true',\n",
        "                                        ax=ax[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHBzVpzoTRHF"
      },
      "source": [
        "## Load and examine data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7hwJvKhSkxt"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Coding Dojo/Lectures - Live Class Materials/Stack 2/Week 5/Titanic.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fziEgKSTTHJm",
        "outputId": "a29ae145-144f-46a4-a782-e852fb80cf24"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 14 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Unnamed: 0   891 non-null    int64  \n",
            " 1   survived     891 non-null    int64  \n",
            " 2   pclass       891 non-null    int64  \n",
            " 3   sex          891 non-null    object \n",
            " 4   age          714 non-null    float64\n",
            " 5   sibsp        891 non-null    int64  \n",
            " 6   parch        891 non-null    int64  \n",
            " 7   fare         891 non-null    float64\n",
            " 8   embarked     889 non-null    object \n",
            " 9   class        891 non-null    object \n",
            " 10  who          891 non-null    object \n",
            " 11  deck         203 non-null    object \n",
            " 12  embark_town  889 non-null    object \n",
            " 13  alive        891 non-null    object \n",
            "dtypes: float64(2), int64(5), object(7)\n",
            "memory usage: 97.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctZIbdQ1NrgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eebbae36-5d32-49ea-8717-0c7f351f57b1"
      },
      "source": [
        "df.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF_eV8VAYAnD"
      },
      "source": [
        "Use a seaborn pairplot to examine the distributions of and correlations between columns (distributions are on the diagonal)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY1tb5l9ZL-z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XcvBU48Z7xo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF02TT3xYXbO"
      },
      "source": [
        "# Class Balance\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vexZ-JnYSpw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t7MnK3xXbgL"
      },
      "source": [
        "#Split the data into training and validation sets\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXdHK3A0dM9S"
      },
      "source": [
        "# Preprocessing Pipeline\n",
        "\n",
        "A ColumnTransformer allows you to apply different preprocessing steps to different columns.  In this case we want to one-hot encode the categorical columns and scale the numeric columns.\n",
        "\n",
        "A ColumnSelector returns certain columns based on their data type.  ColumnTransformer can also just take a list of column names instead if desired."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMzdx4N2QdnT"
      },
      "source": [
        "\n",
        "\n",
        "#column_selectors to tell the column transformers which columns to apply which preprocessing to\n",
        "\n",
        "\n",
        "#imputers, pipelines and tuples\n",
        "\n",
        "\n",
        "#column transformer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAEzo3eFfKgg"
      },
      "source": [
        "# Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JPuJRmIeQ-e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkMY4SyefNOy"
      },
      "source": [
        "# Light GBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6XPS8mHh1rv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDrzlgjqfRiX"
      },
      "source": [
        "# XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7wXtxtSh8gO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B2kCX-t10gJQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-6tNd9cesmF"
      },
      "source": [
        "# Evaluation:\n",
        "\n",
        "1. Which metrics are most important for this business case?  \n",
        "\n",
        "2. According to these metrics, what will this model be good at?  What will it be bad at?\n",
        "\n",
        "# Next Steps:\n",
        "\n",
        "What would you do next to make this model better?\n",
        "\n",
        "1. \n",
        "2. \n",
        "3. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YPTVh_QLLaPr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}